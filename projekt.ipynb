{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lettr</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lettr  x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "0     T      2      8      3     5      1      8     13      0      6      6   \n",
       "1     I      5     12      3     7      2     10      5      5      4     13   \n",
       "2     D      4     11      6     8      6     10      6      2      6     10   \n",
       "3     N      7     11      6     6      3      5      9      4      6      4   \n",
       "4     G      2      1      3     1      1      8      6      6      6      6   \n",
       "\n",
       "   x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
       "0     10      8      0      8      0      8  \n",
       "1      3      9      2      8      4     10  \n",
       "2      3      7      3      7      3      9  \n",
       "3      4     10      6     10      2      8  \n",
       "4      5      9      1      7      5     10  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('letter-recognition.data', sep=\",\")\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filename):  \n",
    "   data = genfromtxt(filename, delimiter=',',dtype=None,encoding=\"UTF8\")[1:]\n",
    "   X = data[:,1:].astype('int32')\n",
    "   y = data[:,0]\n",
    "   return X, y\n",
    "\n",
    "X, y = loadData('letter-recognition.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y_transformed = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# u članku podjela 15000:5000, a kasnije piše 60%:40%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_features=\"sqrt\", max_depth=25, min_samples_split=5)\n",
    "clf.fit(X_train, y_train)\n",
    "decision_trees = clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapNodeIndicesToLeafIndices(tree):\n",
    "   mapping = dict()\n",
    "   node_index, leafIndex = 0, 0\n",
    "   def createMapping(tree, node_index, leafIndex):\n",
    "      if tree.tree_.children_left[node_index] == -1:\n",
    "         mapping[node_index] = leafIndex\n",
    "         leafIndex = leafIndex + 1\n",
    "         return leafIndex\n",
    "      leafIndex = createMapping(tree, tree.tree_.children_left[node_index], leafIndex)\n",
    "      leafIndex = createMapping(tree, tree.tree_.children_right[node_index], leafIndex)\n",
    "      return leafIndex\n",
    "   \n",
    "   createMapping(tree, node_index, leafIndex)\n",
    "   return mapping\n",
    "\n",
    "def getListOfMaps(forest):\n",
    "   return [mapNodeIndicesToLeafIndices(tree) for tree in forest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfIndicesMaps = getListOfMaps(decision_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllLeavesNumeration(listOfIndicesMaps):\n",
    "   num_of_all_forest_leaves = 0\n",
    "   num_of_leaves_so_far = []\n",
    "   n_leaves = len(listOfIndicesMaps[0])\n",
    "   num_of_leaves_so_far.append(n_leaves)\n",
    "   num_of_all_forest_leaves += n_leaves\n",
    "   for t in range(1, len(listOfIndicesMaps), 1):\n",
    "      n_leaves = len(listOfIndicesMaps[t])\n",
    "      num_of_leaves_so_far.append(num_of_leaves_so_far[-1] + n_leaves)\n",
    "      num_of_all_forest_leaves += n_leaves\n",
    "   return num_of_leaves_so_far, num_of_all_forest_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "#creates a SPARE matrix of dimension: num_of_instances x num_of_all_forest_leaves\n",
    "def create_Phi_matrix(X, decision_trees, listOfIndicesMaps):\n",
    "   #dim (br.stabala x br.primjera)\n",
    "   leaf_id_T = np.array([d.apply(X) for d in decision_trees])\n",
    "   #unutra su node_indices, želimo leaf_indices\n",
    "   for t in range(len(leaf_id_T)):\n",
    "      tree_map = listOfIndicesMaps[t]\n",
    "      for i in range(len(X)):\n",
    "         leaf_id_T[t][i] = tree_map[leaf_id_T[t][i]]\n",
    "   num_of_leaves_so_far, num_of_all_forest_leaves = getAllLeavesNumeration(listOfIndicesMaps)\n",
    "   row, col = np.array([]), np.array([])\n",
    "   for i in range(len(decision_trees)):\n",
    "      row = np.concatenate((row, np.arange(len(X))))\n",
    "   col = np.concatenate((col, leaf_id_T[0]))\n",
    "   for t in range(1, len(leaf_id_T), 1):\n",
    "      col = np.concatenate((col, leaf_id_T[t] + num_of_leaves_so_far[t-1]))\n",
    "   data = np.array([1 for i in range(len(X)*len(decision_trees))])\n",
    "   #print(len(row), len(col), len(data))\n",
    "   Phi_matrix = csr_matrix((data, (np.array(row), np.array(col))), shape=(len(X), num_of_all_forest_leaves))\n",
    "   return Phi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_train = create_Phi_matrix(X_train, decision_trees, listOfIndicesMaps)\n",
    "Phi_test = create_Phi_matrix(X_test, decision_trees, listOfIndicesMaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liblinear.liblinearutil import *\n",
    "\n",
    "def optimize(y_train, Phi_train, classification=False, regression=False):\n",
    "   prob  = problem(y_train, Phi_train)\n",
    "   if classification:\n",
    "      param = parameter('-s 2 -c 0.1')\n",
    "   if regression:\n",
    "      param = parameter('-s 11 -c 0.1')\n",
    "   model = train(prob, param)\n",
    "   [W, b] = model.get_decfun()\n",
    "   return model, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, W = optimize(y_train, Phi_train, classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.46% (4823/5000) (classification)\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted,_,_ = predict(y_test, Phi_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def findAdjacentLeaves(decision_trees, listOfIndicesMaps, W):\n",
    "   #print(len(W))\n",
    "   adjacent_leaves = []\n",
    "   n = 0\n",
    "   #num_of_leaves_so_far, _ =  getAllLeavesNumeration(listOfIndicesMaps)\n",
    "   #num_of_leaves_so_far = [0] + num_of_leaves_so_far\n",
    " #....\n",
    "   for t in range(0,len(decision_trees)):\n",
    "      tree_map = listOfIndicesMaps[t]\n",
    "      children_right = decision_trees[t].tree_.children_right\n",
    "      for node_index in tree_map:\n",
    "         sibling_node_index = children_right[node_index-1]\n",
    "         if(sibling_node_index in tree_map):\n",
    "            #sibling is a leaf\n",
    "            #for each pair of adjacent leaves, we first compute the summation of the l2-norm of their leaf vectors to measure the significance\n",
    "            #print(num_of_leaves_so_far[t-1] + tree_map[node_index])\n",
    "            leaf_vector1 = W[n + tree_map[node_index]]\n",
    "            leaf_vector2 = W[n + tree_map[sibling_node_index]]\n",
    "            significance = math.sqrt(math.pow(leaf_vector1, 2)) + math.sqrt(math.pow(leaf_vector2, 2))\n",
    "            adjacent_leaves.append([t, node_index, sibling_node_index, significance])\n",
    "      n+=len(listOfIndicesMaps[t])\n",
    "   return adjacent_leaves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129135\n"
     ]
    }
   ],
   "source": [
    "adjacent_leaves = findAdjacentLeaves(decision_trees, listOfIndicesMaps, W)\n",
    "#sortiraj parove listova po signifikantnosti\n",
    "adjacent_leaves = sorted(adjacent_leaves, key=lambda x: x[3])\n",
    "#print(adjacent_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89, 1850, 1851, 0.0006692291626278761]\n"
     ]
    }
   ],
   "source": [
    "#we empirically prune 10% of leaves in each iteration\n",
    "num_of_pairs_to_prune = round(0.1 * len(W))\n",
    "pairs_to_prune = adjacent_leaves[:num_of_pairs_to_prune]\n",
    "print(pairs_to_prune[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pruning:  two adjacent leaves are merged into one new leaf if the norm of their leaf vectors are close to zeros\n",
    "def pruneTrees(pairs_to_prune, decision_trees):\n",
    "   for p in pairs_to_prune:\n",
    "      t = p[0]\n",
    "      parent_index = p[1] - 1\n",
    "      decision_trees[t].tree_.children_left[parent_index] = -1\n",
    "      decision_trees[t].tree_.children_right[parent_index] = -1\n",
    "   return decision_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_trees = pruneTrees(pairs_to_prune, decision_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_refined_A(X, y, maxIterations, classification=False, regression=False, splitData = True):\n",
    "   if splitData:\n",
    "      le.fit(y)\n",
    "      y_transformed = le.transform(y)\n",
    "      X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size=0.25, random_state=42)\n",
    "   else:\n",
    "      # X , y\n",
    "      #[X_train, X_test], [y_train, y_test]\n",
    "      X_train = X[0]\n",
    "      X_test = X[1]\n",
    "      y_train = y[0]\n",
    "      y_test = y[1]\n",
    "   clf = RandomForestClassifier(n_estimators=100, max_features=\"sqrt\", max_depth=25, min_samples_split=5)\n",
    "   clf.fit(X_train, y_train)\n",
    "   decision_trees = clf.estimators_\n",
    "   i = 0\n",
    "   while i < maxIterations:\n",
    "      i += 1\n",
    "      print(\"iteration \" + str(i) + \":    \", end=\"\")\n",
    "      listOfIndicesMaps = getListOfMaps(decision_trees)\n",
    "      Phi_train = create_Phi_matrix(X_train, decision_trees, listOfIndicesMaps)\n",
    "      Phi_test = create_Phi_matrix(X_test, decision_trees, listOfIndicesMaps)\n",
    "      model, W = optimize(y_train, Phi_train, classification, regression)\n",
    "      predict(y_test, Phi_test, model)\n",
    "      adjacent_leaves = findAdjacentLeaves(decision_trees, listOfIndicesMaps, W)\n",
    "      adjacent_leaves = sorted(adjacent_leaves, key=lambda x: x[3])\n",
    "      num_of_pairs_to_prune = round(0.1 * len(W))\n",
    "      pairs_to_prune = adjacent_leaves[:num_of_pairs_to_prune]\n",
    "      decision_trees = pruneTrees(pairs_to_prune, decision_trees)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1:    Accuracy = 96.58% (4829/5000) (classification)\n",
      "iteration 2:    Accuracy = 96.58% (4829/5000) (classification)\n",
      "iteration 3:    Accuracy = 96.62% (4831/5000) (classification)\n",
      "iteration 4:    Accuracy = 96.5% (4825/5000) (classification)\n",
      "iteration 5:    Accuracy = 96.56% (4828/5000) (classification)\n"
     ]
    }
   ],
   "source": [
    "X, y = loadData('letter-recognition.data')\n",
    "calculate_refined_A(X, y, 5, classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1:    Accuracy = 97.73% (9773/10000) (classification)\n",
      "iteration 2:    Accuracy = 97.75% (9775/10000) (classification)\n",
      "iteration 3:    Accuracy = 97.72% (9772/10000) (classification)\n",
      "iteration 4:    Accuracy = 97.74% (9774/10000) (classification)\n",
      "iteration 5:    "
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "train_data_count = 60_000\n",
    "test_data_count = 10_000\n",
    "\n",
    "import gzip\n",
    "\n",
    "def readGzImages(path,number_of_images):\n",
    "    input_X = gzip.open(path,'r')\n",
    "    input_X.read(16)\n",
    "    buff_X = input_X.read(image_size * image_size * number_of_images)\n",
    "    X = np.frombuffer(buff_X, dtype=np.uint8).astype(np.float32)\n",
    "    X = X.reshape(number_of_images ,image_size * image_size)\n",
    "    return X\n",
    "\n",
    "def readGzLabels(path, number_of_labels):\n",
    "    input_y = gzip.open(path,'r')\n",
    "    input_y.read(8)\n",
    "    buff_y = input_y.read(1 * number_of_labels)\n",
    "    y = np.frombuffer(buff_y, dtype=np.uint8).astype(np.int32)\n",
    "    y = y.reshape(number_of_labels)\n",
    "    return y\n",
    "\n",
    "X_train = readGzImages('train-images-idx3-ubyte.gz', train_data_count)\n",
    "y_train = readGzLabels('train-labels-idx1-ubyte.gz', train_data_count)\n",
    "X_test = readGzImages('t10k-images-idx3-ubyte.gz', test_data_count)\n",
    "y_test = readGzLabels('t10k-labels-idx1-ubyte.gz', test_data_count)\n",
    "calculate_refined_A([X_train, X_test], [y_train, y_test], 5, classification=True, splitData=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1:    Mean squared error = 0.756639 (regression)\n",
      "Squared correlation coefficient = 0.000666831 (regression)\n",
      "iteration 2:    Mean squared error = 0.757375 (regression)\n",
      "Squared correlation coefficient = 0.000701887 (regression)\n",
      "iteration 3:    Mean squared error = 0.761255 (regression)\n",
      "Squared correlation coefficient = 0.000666018 (regression)\n",
      "iteration 4:    Mean squared error = 0.767516 (regression)\n",
      "Squared correlation coefficient = 0.000357401 (regression)\n",
      "iteration 5:    Mean squared error = 0.770906 (regression)\n",
      "Squared correlation coefficient = 0.000423992 (regression)\n",
      "iteration 6:    Mean squared error = 0.777268 (regression)\n",
      "Squared correlation coefficient = 0.000370787 (regression)\n",
      "iteration 7:    Mean squared error = 0.777716 (regression)\n",
      "Squared correlation coefficient = 0.000778296 (regression)\n",
      "iteration 8:    Mean squared error = 0.779471 (regression)\n",
      "Squared correlation coefficient = 0.00108157 (regression)\n",
      "iteration 9:    Mean squared error = 0.790662 (regression)\n",
      "Squared correlation coefficient = 0.000825811 (regression)\n",
      "iteration 10:    Mean squared error = 0.797518 (regression)\n",
      "Squared correlation coefficient = 0.000740605 (regression)\n"
     ]
    }
   ],
   "source": [
    "data = genfromtxt('abalone.data', delimiter=',',dtype=str,encoding=\"UTF8\")\n",
    "X = data[:,1:].astype('float32')\n",
    "y = data[:,0]\n",
    "calculate_refined_A(X, y, 10, regression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1:    Mean squared error = 3.39503 (regression)\n",
      "Squared correlation coefficient = 0.807951 (regression)\n",
      "iteration 2:    Mean squared error = 3.38168 (regression)\n",
      "Squared correlation coefficient = 0.808616 (regression)\n",
      "iteration 3:    Mean squared error = 3.3702 (regression)\n",
      "Squared correlation coefficient = 0.809032 (regression)\n",
      "iteration 4:    Mean squared error = 3.37434 (regression)\n",
      "Squared correlation coefficient = 0.808481 (regression)\n",
      "iteration 5:    Mean squared error = 3.38505 (regression)\n",
      "Squared correlation coefficient = 0.807576 (regression)\n",
      "iteration 6:    Mean squared error = 3.37939 (regression)\n",
      "Squared correlation coefficient = 0.807327 (regression)\n",
      "iteration 7:    Mean squared error = 3.39849 (regression)\n",
      "Squared correlation coefficient = 0.805697 (regression)\n",
      "iteration 8:    Mean squared error = 3.36293 (regression)\n",
      "Squared correlation coefficient = 0.807608 (regression)\n",
      "iteration 9:    Mean squared error = 3.37565 (regression)\n",
      "Squared correlation coefficient = 0.806211 (regression)\n",
      "iteration 10:    Mean squared error = 3.38551 (regression)\n",
      "Squared correlation coefficient = 0.805385 (regression)\n"
     ]
    }
   ],
   "source": [
    "data = genfromtxt('ailerons.data', delimiter=',',dtype=str,encoding=\"UTF8\")\n",
    "X = data[:,:-1].astype('float32')\n",
    "y = data[:,-1]\n",
    "calculate_refined_A(X, y, 10, regression=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ee15d7422c5822bb77f0cd8c9df78032711fade22013277ac41cfabb02f9691"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
